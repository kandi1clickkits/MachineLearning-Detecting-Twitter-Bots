{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6910367b",
   "metadata": {},
   "source": [
    "# Twitter Bot Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a6e823",
   "metadata": {},
   "source": [
    "Twitter Bot Detection App predicts bot from the tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b916621",
   "metadata": {},
   "source": [
    "1. <b>test_data_tweet.csv</b> - Load data to run prediction in this csv file.</br>\n",
    "2. <b>Output_data.csv</b> - Writes predicted output in this file in the column bot.\n",
    "     \n",
    "<b>Note:</b> Update variables under <b>Variables</b> section to configure inputs if required before running the notebook.\n",
    "\n",
    "To run notebook cell by cell, click on a cell and click <b>Run</b> button below the <b>Menu</b> bar. Or to run all cells, select <b>Cell --> Run All</b> from Menu bar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6799d40",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f96db28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv \n",
    "from pandas.io.json import json_normalize #package for flattening json in pandas df#load json object\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['patch.force_edgecolor'] = True\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c52e24",
   "metadata": {},
   "source": [
    "### Variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62386e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "InputFileName = \"test_data_tweet.csv\"\n",
    "OutputFileName = \"Output_data.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621bb2e5",
   "metadata": {},
   "source": [
    "### Generate Bearer Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a6ad969",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
      " 27 60368   27 16384    0     0   8765      0  0:00:06  0:00:01  0:00:05  8766\n",
      "100 60368  100 60368    0     0  31534      0  0:00:01  0:00:01 --:--:-- 31540\n"
     ]
    }
   ],
   "source": [
    "!curl --request GET  --url \"https://api.twitter.com/2/tweets/search/recent?query=%23covid&tweet.fields=public_metrics&expansions=author_id&user.fields=description,id,name,username,verified,public_metrics&max_results=100\" --header \"Authorization: Bearer <bearer token>\" --output OutputFile.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "757a78a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"OutputFile.json\",encoding='utf-8') as f:\n",
    "    d = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce0f55b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV Loaded Successfully....\n"
     ]
    }
   ],
   "source": [
    "fields = ['screen_name','name','description','verified','listed_count','id']\n",
    "with open(InputFileName, 'w',encoding='utf-8',newline='') as csvfile: \n",
    "    csvwriter = csv.writer(csvfile) \n",
    "    csvwriter.writerow(fields)\n",
    "    for row in d['includes']['users']:\n",
    "        rowval=[]\n",
    "        rowval.append(row['username'])\n",
    "        rowval.append(row['name'])\n",
    "        rowval.append(row['description'])\n",
    "        rowval.append(row['verified'])\n",
    "        rowval.append(row['public_metrics']['listed_count'])\n",
    "        rowval.append(row['id'])\n",
    "        \n",
    "        csvwriter.writerow(rowval)\n",
    "print(\"CSV Loaded Successfully....\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16642a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'https://raw.githubusercontent.com/jubins/ML-TwitterBotDetection/master/FinalProjectAndCode/kaggle_data/'\n",
    "file= filepath+'training_data_2_csv_UTF.csv'\n",
    "\n",
    "training_data = pd.read_csv(file)\n",
    "bots = training_data[training_data.bot==1]\n",
    "nonbots = training_data[training_data.bot==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a58f51",
   "metadata": {},
   "source": [
    "#### Our Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "649c52e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "class twitter_bot(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def perform_train_test_split(df):\n",
    "        msk = np.random.rand(len(df)) < 0.75\n",
    "        train, test = df[msk], df[~msk]\n",
    "        X_train, y_train = train, train.iloc[:,-1]\n",
    "        X_test, y_test = test, test.iloc[:, -1]\n",
    "        return (X_train, y_train, X_test, y_test)\n",
    "\n",
    "    def bot_prediction_algorithm(df):\n",
    "        # creating copy of dataframe\n",
    "        train_df = df.copy()\n",
    "        if(not 'bot' in train_df.columns):\n",
    "            train_df['bot']=pd.Series()\n",
    "        # performing feature engineering on id and verfied columns\n",
    "        # converting id to int\n",
    "        train_df['id'] = train_df.id.apply(lambda x: int(x))\n",
    "        #We created two bag of words because more bow is stringent on test data, so on all small dataset we check less\n",
    "        if train_df.shape[0]>600:\n",
    "            #bag_of_words_for_bot\n",
    "            bag_of_words_bot = r'bot|b0t|cannabis|tweet me|mishear|follow me|updates every|gorilla|yes_ofc|forget' \\\n",
    "                           r'expos|kill|clit|bbb|butt|fuck|XXX|sex|truthe|fake|anony|free|virus|funky|RNA|kuck|jargon' \\\n",
    "                           r'nerd|swag|jack|bang|bonsai|chick|prison|paper|pokem|xx|freak|ffd|dunia|clone|genie|bbb' \\\n",
    "                           r'ffd|onlyman|emoji|joke|troll|droop|free|every|wow|cheese|yeah|bio|magic|wizard|face'\n",
    "        else:\n",
    "            # bag_of_words_for_bot\n",
    "            bag_of_words_bot = r'bot|b0t|cannabis|mishear|updates every'\n",
    "\n",
    "        # converting verified into vectors\n",
    "        train_df['verified'] = train_df.verified.apply(lambda x: 1 if ((x == True) or x == 'TRUE') else 0)\n",
    "\n",
    "        # check if the name contains bot or screenname contains b0t\n",
    "        condition = ((train_df.name.str.contains(bag_of_words_bot, case=False, na=False)) |\n",
    "                     (train_df.description.str.contains(bag_of_words_bot, case=False, na=False)) |\n",
    "                     (train_df.screen_name.str.contains(bag_of_words_bot, case=False, na=False)) \n",
    "                     )  # these all are bots\n",
    "        predicted_df = train_df[condition]  # these all are bots\n",
    "        predicted_df.bot = 1\n",
    "        predicted_df = predicted_df[['id', 'bot']]\n",
    "\n",
    "        # check if the user is verified\n",
    "        verified_df = train_df[~condition]\n",
    "        condition = (verified_df.verified == 1)  # these all are nonbots\n",
    "        predicted_df1 = verified_df[condition][['id', 'bot']]\n",
    "        predicted_df1.bot = 0\n",
    "        predicted_df = pd.concat([predicted_df, predicted_df1])\n",
    "\n",
    "        # check if description contains buzzfeed\n",
    "        buzzfeed_df = verified_df[~condition]\n",
    "        condition = (buzzfeed_df.description.str.contains(\"buzzfeed\", case=False, na=False))  # these all are nonbots\n",
    "        predicted_df1 = buzzfeed_df[buzzfeed_df.description.str.contains(\"buzzfeed\", case=False, na=False)][['id', 'bot']]\n",
    "        predicted_df1.bot = 0\n",
    "        predicted_df = pd.concat([predicted_df, predicted_df1])\n",
    "\n",
    "        # check if listed_count>16000\n",
    "        listed_count_df = buzzfeed_df[~condition]\n",
    "        listed_count_df.listed_count = listed_count_df.listed_count.apply(lambda x: 0 if x == 'None' else x)\n",
    "        listed_count_df.listed_count = listed_count_df.listed_count.apply(lambda x: int(x))\n",
    "        condition = (listed_count_df.listed_count > 16000)  # these all are nonbots\n",
    "        predicted_df1 = listed_count_df[condition][['id', 'bot']]\n",
    "        predicted_df1.bot = 0\n",
    "        predicted_df = pd.concat([predicted_df, predicted_df1])\n",
    "\n",
    "        #remaining\n",
    "        predicted_df1 = listed_count_df[~condition][['id', 'bot']]\n",
    "        predicted_df1.bot = 0 # these all are nonbots\n",
    "        predicted_df = pd.concat([predicted_df, predicted_df1])\n",
    "        return predicted_df\n",
    "\n",
    "    def get_predicted_and_true_values(features, target):\n",
    "        y_pred, y_true = twitter_bot.bot_prediction_algorithm(features).bot.tolist(), target.tolist()\n",
    "        return (y_pred, y_true)\n",
    "\n",
    "    def get_accuracy_score(df):\n",
    "        (X_train, y_train, X_test, y_test) = twitter_bot.perform_train_test_split(df)\n",
    "        # predictions on training data\n",
    "        y_pred_train, y_true_train = twitter_bot.get_predicted_and_true_values(X_train, y_train)\n",
    "        train_acc = metrics.accuracy_score(y_pred_train, y_true_train)\n",
    "        #predictions on test data\n",
    "        y_pred_test, y_true_test = twitter_bot.get_predicted_and_true_values(X_test, y_test)\n",
    "        test_acc = metrics.accuracy_score(y_pred_test, y_true_test)\n",
    "        return (train_acc, test_acc)\n",
    "\n",
    "    def plot_roc_curve(df):\n",
    "        (X_train, y_train, X_test, y_test) = twitter_bot.perform_train_test_split(df)\n",
    "        # Train ROC\n",
    "        y_pred_train, y_true = twitter_bot.get_predicted_and_true_values(X_train, y_train)\n",
    "        scores = np.linspace(start=0.01, stop=0.9, num=len(y_true))\n",
    "        fpr_train, tpr_train, threshold = metrics.roc_curve(y_pred_train, scores, pos_label=0)\n",
    "        plt.plot(fpr_train, tpr_train, label='Train AUC: %5f' % metrics.auc(fpr_train, tpr_train), color='darkblue')\n",
    "        #Test ROC\n",
    "        y_pred_test, y_true = twitter_bot.get_predicted_and_true_values(X_test, y_test)\n",
    "        scores = np.linspace(start=0.01, stop=0.9, num=len(y_true))\n",
    "        fpr_test, tpr_test, threshold = metrics.roc_curve(y_pred_test, scores, pos_label=0)\n",
    "        plt.plot(fpr_test,tpr_test, label='Test AUC: %5f' %metrics.auc(fpr_test,tpr_test), ls='--', color='red')\n",
    "        #Misc\n",
    "        plt.xlim([-0.1,1])\n",
    "        plt.title(\"Reciever Operating Characteristic (ROC)\")\n",
    "        plt.xlabel(\"False Positive Rate (FPR)\")\n",
    "        plt.ylabel(\"True Positive Rate (TPR)\")\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8040305d",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9adb0725",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "test_df = pd.read_csv(InputFileName,encoding='ISO-8859-1')\n",
    "#predicting test data results\n",
    "predicted_df = twitter_bot.bot_prediction_algorithm(test_df)\n",
    "test_df['bot'] = predicted_df['bot']\n",
    "test_df.to_csv(OutputFileName, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b1f6bf",
   "metadata": {},
   "source": [
    "### Thank you !!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
